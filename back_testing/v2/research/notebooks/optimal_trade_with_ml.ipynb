{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbf960d00bf8447f58cc83a94e3f130e4",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/Users/rosscopeland/Desktop/personal/code/vivaldi/back_testing\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('../../../')\n",
    "print(os.getcwd())\n",
    "from v2.model import Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from v2.model import Trading\n",
    "from v2.strategy.indicators.smma import SMMA\n",
    "from v2.strategy.indicators.stochastic_oscillator import StochasticOscillator\n",
    "from v2.strategy.indicators.bollinger_bands import BollingerBands\n",
    "from v2.strategy.indicators.rsi import RSI\n",
    "from v2.strategy.indicators.macd import MACD\n",
    "from v2.strategy.indicators.param import Param\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    my_config = {}\n",
    "    with open('config.config') as config:\n",
    "        for line in config:\n",
    "            args = line.split('=')\n",
    "            my_config[args[0]] = args[1].rstrip().split(',')\n",
    "    return my_config\n",
    "\n",
    "model = Trading(load_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only one data set rn\n",
    "if len(model.dfs) != 1:\n",
    "    raise ValueError(\"only one dataset to be used here\")\n",
    "\n",
    "dataset = model.dfs[0][0]\n",
    "buy_prices = []\n",
    "buy_times = []\n",
    "sell_prices = []\n",
    "sell_times = []\n",
    "name = ''\n",
    "candle, buys, sells = None, None, None\n",
    "fee = 0.0026\n",
    "\n",
    "\n",
    "cur_min = sys.maxsize\n",
    "cur_max = 0.00\n",
    "cur_min_time = 00.0\n",
    "cur_max_time = 00.0\n",
    "last_buy_price = 000.00\n",
    "last_buy_time = 000.00\n",
    "sell_time = 0000.0\n",
    "looking_for_buy = True\n",
    "for row in dataset.itertuples():\n",
    "    close = row.close\n",
    "    time = row.time\n",
    "    if looking_for_buy:\n",
    "        if close < cur_min:\n",
    "            cur_min = close\n",
    "            cur_min_time = time\n",
    "            cur_max = close\n",
    "            cur_max_time = time\n",
    "        elif close > cur_max:\n",
    "            cur_max = close\n",
    "            cur_max_time = time\n",
    "            delta = cur_max - cur_min\n",
    "            if delta > ((cur_min * fee) + (cur_max * fee)):\n",
    "                looking_for_buy = False\n",
    "                last_buy_price = cur_min\n",
    "                last_buy_time = cur_min_time\n",
    "    else:\n",
    "        trade_fee = ((cur_min * fee) + (cur_max * fee))\n",
    "        if close > cur_max:\n",
    "            cur_max = close\n",
    "            cur_max_time = time\n",
    "        elif close < cur_max - trade_fee:\n",
    "            looking_for_buy = True\n",
    "            buy_prices.append(cur_min)\n",
    "            buy_times.append(cur_min_time)\n",
    "            sell_prices.append(cur_max)\n",
    "            sell_times.append(cur_max_time)\n",
    "            cur_min = close\n",
    "            cur_min_time = time\n",
    "            cur_max = close\n",
    "            cur_max_time = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making set of buy and sell times\n",
    "optimal_buy_times = set(sell_times)\n",
    "optimal_sell_times = set(buy_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_peak_trough(row):\n",
    "    if row.time in optimal_buy_times and row.time in optimal_sell_times:\n",
    "        raise ValueError(\"There's something wrong with the algo\")\n",
    "    elif row.time in optimal_buy_times:\n",
    "        return -1\n",
    "    elif row.time in optimal_sell_times:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"peak_trough_wait\"] = dataset.apply(lambda x: identify_peak_trough(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "33601 33601\n"
    }
   ],
   "source": [
    "print(len(optimal_buy_times), len(optimal_sell_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets add in some indicators\n",
    "training_set = dataset\n",
    "appended_dataset = pd.DataFrame()\n",
    "ema_fast = Param(5, 10000, 0, 'ema_fast', 60)\n",
    "ema_slow = Param(6, 10001, 0, 'ema_slow', 120)\n",
    "signal = Param(5, 10001, 0, 'signal', 90)\n",
    "macd_ = MACD(_params=[ema_fast, ema_slow, signal], _name='macd')\n",
    "macd_.genData(training_set, gen_new_values=False)\n",
    "boll_period = Param(5, 10000, 0, 'period', 90)\n",
    "boll_bands = BollingerBands(_params=[boll_period], _name='bollinger_bands')\n",
    "boll_bands.genData(training_set, gen_new_values=False)\n",
    "stoch_highlow = Param(5, 10000, 0, 'highlow_range', 90.0)\n",
    "stoch_k = Param(5, 10000, 0, 'k_period', 270.0)\n",
    "stoch_oscillator = StochasticOscillator(_params=[stoch_highlow, stoch_k], _name='stochastic_oscillator')\n",
    "stoch_oscillator.genData(training_set, gen_new_values=False)\n",
    "rsi_period = Param(5, 10000, 0, 'period', 90.0)\n",
    "rsi_ = RSI(_params=[rsi_period], _name='rsi')\n",
    "rsi_.genData(training_set, gen_new_values=False)\n",
    "smma_period = Param(5, 10000, 0, 'period', 90.0)\n",
    "smma_ = SMMA(_params=[smma_period], _name='smma')\n",
    "smma_.genData(training_set, gen_new_values=False)\n",
    "training_set['slope'] = (training_set['close'].rolling(window=30).max() - training_set['close'].rolling(window=30).min()) / training_set['close'].rolling(window=30).max()\n",
    "training_set = training_set.dropna()\n",
    "appended_dataset = appended_dataset.append(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               time        open        high         low       close    volume  \\\n358      1383503820   207.67198   207.67198   207.67198   207.67198  0.100000   \n359      1383505860   207.43988   207.43988   206.89000   207.01377  1.263692   \n360      1383507660   207.59295   207.75000   207.59295   207.75000  0.100000   \n361      1383507720   207.75000   207.75000   207.75000   207.75000  0.100000   \n362      1383510600   207.75000   207.75000   207.75000   207.75000  0.314611   \n...             ...         ...         ...         ...         ...       ...   \n1737853  1590987240  9548.10000  9549.80000  9548.10000  9549.80000  0.599862   \n1737854  1590987300  9546.20000  9546.20000  9546.20000  9546.20000  0.114211   \n1737855  1590987360  9547.40000  9547.40000  9544.00000  9545.20000  7.608574   \n1737856  1590987420  9543.90000  9544.00000  9543.90000  9543.90000  0.618188   \n1737857  1590987480  9543.80000  9543.80000  9541.00000  9541.00000  1.717000   \n\n         trades  peak_trough_wait     ema_slow     ema_fast  ...    stosc_k  \\\n358           1                 0   203.646855   205.570957  ...   4.275846   \n359           5                 0   203.702506   205.618262  ...  13.776266   \n360           2                 0   203.769407   205.688155  ...   3.149727   \n361           1                 0   203.835202   205.755757  ...   3.149727   \n362           1                 0   203.899909   205.821142  ...   3.149727   \n...         ...               ...          ...          ...  ...        ...   \n1737853      15                 0  9546.714275  9555.564116  ...  60.864865   \n1737854       2                 0  9546.705775  9555.257096  ...  64.756757   \n1737855      15                 0  9546.680886  9554.927355  ...  65.837838   \n1737856       5                 0  9546.634921  9554.565802  ...  67.243243   \n1737857       5                 0  9546.541781  9554.121022  ...  70.378378   \n\n           stosc_d  rsi_diff    rsi_u    rsi_d  rsi_smma_u  rsi_smma_d  \\\n358      23.660815  -0.00418  0.00000  0.00418    0.328056    0.243793   \n359      23.698312  -0.65821  0.00000  0.65821    0.324344    0.248482   \n360      23.696407   0.73623  0.73623  0.00000    0.329004    0.245671   \n361      23.694475   0.00000  0.00000  0.00000    0.325282    0.242892   \n362      23.696210   0.00000  0.00000  0.00000    0.321603    0.240145   \n...            ...       ...      ...      ...         ...         ...   \n1737853  26.509862   5.20000  5.20000  0.00000    2.058900    1.916728   \n1737854  26.664156  -3.60000  0.00000  3.60000    2.036023    1.935431   \n1737855  26.792956  -1.00000  0.00000  1.00000    2.013401    1.925037   \n1737856  26.892546  -1.30000  0.00000  1.30000    1.991030    1.918092   \n1737857  26.957205  -2.90000  0.00000  2.90000    1.968907    1.929002   \n\n               rsi         smma     slope  \n358      57.367632   201.724654  0.013416  \n359      56.621691   201.784494  0.013416  \n360      57.250430   201.851973  0.013767  \n361      57.250430   201.918675  0.012649  \n362      57.250430   201.984609  0.009771  \n...            ...          ...       ...  \n1737853  51.788049  9537.146659  0.006402  \n1737854  51.266446  9537.247252  0.006402  \n1737855  51.121814  9537.335616  0.006402  \n1737856  50.932915  9537.408553  0.006475  \n1737857  50.511876  9537.448458  0.006777  \n\n[1737224 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>trades</th>\n      <th>peak_trough_wait</th>\n      <th>ema_slow</th>\n      <th>ema_fast</th>\n      <th>...</th>\n      <th>stosc_k</th>\n      <th>stosc_d</th>\n      <th>rsi_diff</th>\n      <th>rsi_u</th>\n      <th>rsi_d</th>\n      <th>rsi_smma_u</th>\n      <th>rsi_smma_d</th>\n      <th>rsi</th>\n      <th>smma</th>\n      <th>slope</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>358</th>\n      <td>1383503820</td>\n      <td>207.67198</td>\n      <td>207.67198</td>\n      <td>207.67198</td>\n      <td>207.67198</td>\n      <td>0.100000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>203.646855</td>\n      <td>205.570957</td>\n      <td>...</td>\n      <td>4.275846</td>\n      <td>23.660815</td>\n      <td>-0.00418</td>\n      <td>0.00000</td>\n      <td>0.00418</td>\n      <td>0.328056</td>\n      <td>0.243793</td>\n      <td>57.367632</td>\n      <td>201.724654</td>\n      <td>0.013416</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>1383505860</td>\n      <td>207.43988</td>\n      <td>207.43988</td>\n      <td>206.89000</td>\n      <td>207.01377</td>\n      <td>1.263692</td>\n      <td>5</td>\n      <td>0</td>\n      <td>203.702506</td>\n      <td>205.618262</td>\n      <td>...</td>\n      <td>13.776266</td>\n      <td>23.698312</td>\n      <td>-0.65821</td>\n      <td>0.00000</td>\n      <td>0.65821</td>\n      <td>0.324344</td>\n      <td>0.248482</td>\n      <td>56.621691</td>\n      <td>201.784494</td>\n      <td>0.013416</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>1383507660</td>\n      <td>207.59295</td>\n      <td>207.75000</td>\n      <td>207.59295</td>\n      <td>207.75000</td>\n      <td>0.100000</td>\n      <td>2</td>\n      <td>0</td>\n      <td>203.769407</td>\n      <td>205.688155</td>\n      <td>...</td>\n      <td>3.149727</td>\n      <td>23.696407</td>\n      <td>0.73623</td>\n      <td>0.73623</td>\n      <td>0.00000</td>\n      <td>0.329004</td>\n      <td>0.245671</td>\n      <td>57.250430</td>\n      <td>201.851973</td>\n      <td>0.013767</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>1383507720</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>0.100000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>203.835202</td>\n      <td>205.755757</td>\n      <td>...</td>\n      <td>3.149727</td>\n      <td>23.694475</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.325282</td>\n      <td>0.242892</td>\n      <td>57.250430</td>\n      <td>201.918675</td>\n      <td>0.012649</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>1383510600</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>0.314611</td>\n      <td>1</td>\n      <td>0</td>\n      <td>203.899909</td>\n      <td>205.821142</td>\n      <td>...</td>\n      <td>3.149727</td>\n      <td>23.696210</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.321603</td>\n      <td>0.240145</td>\n      <td>57.250430</td>\n      <td>201.984609</td>\n      <td>0.009771</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1737853</th>\n      <td>1590987240</td>\n      <td>9548.10000</td>\n      <td>9549.80000</td>\n      <td>9548.10000</td>\n      <td>9549.80000</td>\n      <td>0.599862</td>\n      <td>15</td>\n      <td>0</td>\n      <td>9546.714275</td>\n      <td>9555.564116</td>\n      <td>...</td>\n      <td>60.864865</td>\n      <td>26.509862</td>\n      <td>5.20000</td>\n      <td>5.20000</td>\n      <td>0.00000</td>\n      <td>2.058900</td>\n      <td>1.916728</td>\n      <td>51.788049</td>\n      <td>9537.146659</td>\n      <td>0.006402</td>\n    </tr>\n    <tr>\n      <th>1737854</th>\n      <td>1590987300</td>\n      <td>9546.20000</td>\n      <td>9546.20000</td>\n      <td>9546.20000</td>\n      <td>9546.20000</td>\n      <td>0.114211</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9546.705775</td>\n      <td>9555.257096</td>\n      <td>...</td>\n      <td>64.756757</td>\n      <td>26.664156</td>\n      <td>-3.60000</td>\n      <td>0.00000</td>\n      <td>3.60000</td>\n      <td>2.036023</td>\n      <td>1.935431</td>\n      <td>51.266446</td>\n      <td>9537.247252</td>\n      <td>0.006402</td>\n    </tr>\n    <tr>\n      <th>1737855</th>\n      <td>1590987360</td>\n      <td>9547.40000</td>\n      <td>9547.40000</td>\n      <td>9544.00000</td>\n      <td>9545.20000</td>\n      <td>7.608574</td>\n      <td>15</td>\n      <td>0</td>\n      <td>9546.680886</td>\n      <td>9554.927355</td>\n      <td>...</td>\n      <td>65.837838</td>\n      <td>26.792956</td>\n      <td>-1.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>2.013401</td>\n      <td>1.925037</td>\n      <td>51.121814</td>\n      <td>9537.335616</td>\n      <td>0.006402</td>\n    </tr>\n    <tr>\n      <th>1737856</th>\n      <td>1590987420</td>\n      <td>9543.90000</td>\n      <td>9544.00000</td>\n      <td>9543.90000</td>\n      <td>9543.90000</td>\n      <td>0.618188</td>\n      <td>5</td>\n      <td>0</td>\n      <td>9546.634921</td>\n      <td>9554.565802</td>\n      <td>...</td>\n      <td>67.243243</td>\n      <td>26.892546</td>\n      <td>-1.30000</td>\n      <td>0.00000</td>\n      <td>1.30000</td>\n      <td>1.991030</td>\n      <td>1.918092</td>\n      <td>50.932915</td>\n      <td>9537.408553</td>\n      <td>0.006475</td>\n    </tr>\n    <tr>\n      <th>1737857</th>\n      <td>1590987480</td>\n      <td>9543.80000</td>\n      <td>9543.80000</td>\n      <td>9541.00000</td>\n      <td>9541.00000</td>\n      <td>1.717000</td>\n      <td>5</td>\n      <td>0</td>\n      <td>9546.541781</td>\n      <td>9554.121022</td>\n      <td>...</td>\n      <td>70.378378</td>\n      <td>26.957205</td>\n      <td>-2.90000</td>\n      <td>0.00000</td>\n      <td>2.90000</td>\n      <td>1.968907</td>\n      <td>1.929002</td>\n      <td>50.511876</td>\n      <td>9537.448458</td>\n      <td>0.006777</td>\n    </tr>\n  </tbody>\n</table>\n<p>1737224 rows × 29 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "appended_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data and such. Split so that may use model predictions as features\n",
    "X = appended_dataset.drop(\"peak_trough_wait\", axis=1)\n",
    "y = appended_dataset[[\"peak_trough_wait\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9356962972556807"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#lets test out some classifying models\n",
    "#Decision Tree\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(X_train.values, y_train.values)\n",
    "dec_tree.score(X_test.values, y_test.values)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "<ipython-input-14-323335def364>:3: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9806674437680784"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#random forest\n",
    "ran_forest = RandomForestClassifier(n_jobs = -1)\n",
    "ran_forest.fit(X_train.values, y_train.values)\n",
    "ran_forest.score(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "30264 1329251 30264\n"
    }
   ],
   "source": [
    "#weights for rf\n",
    "y_vals = y_train.values\n",
    "\n",
    "buy_weight = len([x for x in y_vals if x== -1])\n",
    "sell_weight = len([x for x in y_vals if x == 1])\n",
    "zero_weight = len([x for x in y_vals if x != -1 and x != 1])\n",
    "print(buy_weight, zero_weight, sell_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "<ipython-input-16-1a9723687244>:4: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9739584682467729"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#using rf model with weighted classes\n",
    "class_weights = {-1: buy_weight, 0: zero_weight, 1: sell_weight}\n",
    "weight_rf_forest = RandomForestClassifier(n_jobs=-1, class_weight=class_weights)\n",
    "weight_rf_forest.fit(X_train, y_train)\n",
    "weight_rf_forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9793291024478694"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "boost = XGBClassifier(n_jobs= -1)\n",
    "boost.fit(X_train.values, y_train.values)\n",
    "boost.score(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights for boost\n",
    "boost_weights = []\n",
    "for x in y_vals:\n",
    "    if x == 0:\n",
    "        boost_weights.append(zero_weight/(buy_weight + zero_weight + sell_weight))\n",
    "    elif x == 1:\n",
    "        boost_weights.append(sell_weight/(buy_weight + zero_weight + sell_weight))\n",
    "    elif x == -1:\n",
    "        boost_weights.append(buy_weight/(buy_weight + zero_weight + sell_weight))\n",
    "    else:\n",
    "        raise ValueError(\"this is the value in validation data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9810675070874527"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "boost = XGBClassifier(n_jobs= -1)\n",
    "boost.fit(X_train.values, y_train.values, sample_weight=boost_weights)\n",
    "boost.score(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9810675070874527"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train.values, y_train.values)\n",
    "log_reg.score(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               time         open         high          low        close  \\\n358      1383503820    207.67198    207.67198    207.67198    207.67198   \n359      1383505860    207.43988    207.43988    206.89000    207.01377   \n360      1383507660    207.59295    207.75000    207.59295    207.75000   \n361      1383507720    207.75000    207.75000    207.75000    207.75000   \n362      1383510600    207.75000    207.75000    207.75000    207.75000   \n...             ...          ...          ...          ...          ...   \n1390408  1568168400  10081.90000  10081.90000  10075.10000  10075.20000   \n1390409  1568168460  10075.20000  10075.20000  10075.20000  10075.20000   \n1390410  1568168580  10073.20000  10073.60000  10073.20000  10073.60000   \n1390411  1568168640  10073.50000  10073.90000  10073.50000  10073.90000   \n1390412  1568168700  10073.00000  10079.40000  10073.00000  10073.50000   \n\n           volume  trades      ema_slow      ema_fast      macd  ...  \\\n358      0.100000       1    203.646855    205.570957  1.924102  ...   \n359      1.263692       5    203.702506    205.618262  1.915756  ...   \n360      0.100000       2    203.769407    205.688155  1.918748  ...   \n361      0.100000       1    203.835202    205.755757  1.920555  ...   \n362      0.314611       1    203.899909    205.821142  1.921233  ...   \n...           ...     ...           ...           ...       ...  ...   \n1390408  0.444556       9  10109.184922  10100.992946 -8.191976  ...   \n1390409  0.010462       1  10108.623188  10100.147276 -8.475912  ...   \n1390410  0.052200       2  10108.044292  10099.276873 -8.767419  ...   \n1390411  0.015000       2  10107.479924  10098.444845 -9.035079  ...   \n1390412  1.249396      15  10106.918272  10097.626981 -9.291291  ...   \n\n           stosc_k    stosc_d  rsi_diff    rsi_u    rsi_d  rsi_smma_u  \\\n358       4.275846  23.660815  -0.00418  0.00000  0.00418    0.328056   \n359      13.776266  23.698312  -0.65821  0.00000  0.65821    0.324344   \n360       3.149727  23.696407   0.73623  0.73623  0.00000    0.329004   \n361       3.149727  23.694475   0.00000  0.00000  0.00000    0.325282   \n362       3.149727  23.696210   0.00000  0.00000  0.00000    0.321603   \n...            ...        ...       ...      ...      ...         ...   \n1390408  95.321637  51.682985  -6.50000  0.00000  6.50000    1.748165   \n1390409  95.252226  52.020408   0.00000  0.00000  0.00000    1.728740   \n1390410  96.834817  52.355187  -1.60000  0.00000  1.60000    1.709532   \n1390411  96.482412  52.689484   0.30000  0.30000  0.00000    1.693871   \n1390412  96.884422  52.979728  -0.40000  0.00000  0.40000    1.675050   \n\n         rsi_smma_d        rsi          smma     slope  \n358        0.243793  57.367632    201.724654  0.013416  \n359        0.248482  56.621691    201.784494  0.013416  \n360        0.245671  57.250430    201.851973  0.013767  \n361        0.242892  57.250430    201.918675  0.012649  \n362        0.240145  57.250430    201.984609  0.009771  \n...             ...        ...           ...       ...  \n1390408    2.127896  45.101577  10108.996124  0.003531  \n1390409    2.104253  45.101577  10108.620612  0.002959  \n1390410    2.098650  44.891028  10108.231494  0.003058  \n1390411    2.075332  44.939765  10107.850033  0.003058  \n1390412    2.056717  44.886242  10107.468366  0.003068  \n\n[1389779 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>trades</th>\n      <th>ema_slow</th>\n      <th>ema_fast</th>\n      <th>macd</th>\n      <th>...</th>\n      <th>stosc_k</th>\n      <th>stosc_d</th>\n      <th>rsi_diff</th>\n      <th>rsi_u</th>\n      <th>rsi_d</th>\n      <th>rsi_smma_u</th>\n      <th>rsi_smma_d</th>\n      <th>rsi</th>\n      <th>smma</th>\n      <th>slope</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>358</th>\n      <td>1383503820</td>\n      <td>207.67198</td>\n      <td>207.67198</td>\n      <td>207.67198</td>\n      <td>207.67198</td>\n      <td>0.100000</td>\n      <td>1</td>\n      <td>203.646855</td>\n      <td>205.570957</td>\n      <td>1.924102</td>\n      <td>...</td>\n      <td>4.275846</td>\n      <td>23.660815</td>\n      <td>-0.00418</td>\n      <td>0.00000</td>\n      <td>0.00418</td>\n      <td>0.328056</td>\n      <td>0.243793</td>\n      <td>57.367632</td>\n      <td>201.724654</td>\n      <td>0.013416</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>1383505860</td>\n      <td>207.43988</td>\n      <td>207.43988</td>\n      <td>206.89000</td>\n      <td>207.01377</td>\n      <td>1.263692</td>\n      <td>5</td>\n      <td>203.702506</td>\n      <td>205.618262</td>\n      <td>1.915756</td>\n      <td>...</td>\n      <td>13.776266</td>\n      <td>23.698312</td>\n      <td>-0.65821</td>\n      <td>0.00000</td>\n      <td>0.65821</td>\n      <td>0.324344</td>\n      <td>0.248482</td>\n      <td>56.621691</td>\n      <td>201.784494</td>\n      <td>0.013416</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>1383507660</td>\n      <td>207.59295</td>\n      <td>207.75000</td>\n      <td>207.59295</td>\n      <td>207.75000</td>\n      <td>0.100000</td>\n      <td>2</td>\n      <td>203.769407</td>\n      <td>205.688155</td>\n      <td>1.918748</td>\n      <td>...</td>\n      <td>3.149727</td>\n      <td>23.696407</td>\n      <td>0.73623</td>\n      <td>0.73623</td>\n      <td>0.00000</td>\n      <td>0.329004</td>\n      <td>0.245671</td>\n      <td>57.250430</td>\n      <td>201.851973</td>\n      <td>0.013767</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>1383507720</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>0.100000</td>\n      <td>1</td>\n      <td>203.835202</td>\n      <td>205.755757</td>\n      <td>1.920555</td>\n      <td>...</td>\n      <td>3.149727</td>\n      <td>23.694475</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.325282</td>\n      <td>0.242892</td>\n      <td>57.250430</td>\n      <td>201.918675</td>\n      <td>0.012649</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>1383510600</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>207.75000</td>\n      <td>0.314611</td>\n      <td>1</td>\n      <td>203.899909</td>\n      <td>205.821142</td>\n      <td>1.921233</td>\n      <td>...</td>\n      <td>3.149727</td>\n      <td>23.696210</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.321603</td>\n      <td>0.240145</td>\n      <td>57.250430</td>\n      <td>201.984609</td>\n      <td>0.009771</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1390408</th>\n      <td>1568168400</td>\n      <td>10081.90000</td>\n      <td>10081.90000</td>\n      <td>10075.10000</td>\n      <td>10075.20000</td>\n      <td>0.444556</td>\n      <td>9</td>\n      <td>10109.184922</td>\n      <td>10100.992946</td>\n      <td>-8.191976</td>\n      <td>...</td>\n      <td>95.321637</td>\n      <td>51.682985</td>\n      <td>-6.50000</td>\n      <td>0.00000</td>\n      <td>6.50000</td>\n      <td>1.748165</td>\n      <td>2.127896</td>\n      <td>45.101577</td>\n      <td>10108.996124</td>\n      <td>0.003531</td>\n    </tr>\n    <tr>\n      <th>1390409</th>\n      <td>1568168460</td>\n      <td>10075.20000</td>\n      <td>10075.20000</td>\n      <td>10075.20000</td>\n      <td>10075.20000</td>\n      <td>0.010462</td>\n      <td>1</td>\n      <td>10108.623188</td>\n      <td>10100.147276</td>\n      <td>-8.475912</td>\n      <td>...</td>\n      <td>95.252226</td>\n      <td>52.020408</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1.728740</td>\n      <td>2.104253</td>\n      <td>45.101577</td>\n      <td>10108.620612</td>\n      <td>0.002959</td>\n    </tr>\n    <tr>\n      <th>1390410</th>\n      <td>1568168580</td>\n      <td>10073.20000</td>\n      <td>10073.60000</td>\n      <td>10073.20000</td>\n      <td>10073.60000</td>\n      <td>0.052200</td>\n      <td>2</td>\n      <td>10108.044292</td>\n      <td>10099.276873</td>\n      <td>-8.767419</td>\n      <td>...</td>\n      <td>96.834817</td>\n      <td>52.355187</td>\n      <td>-1.60000</td>\n      <td>0.00000</td>\n      <td>1.60000</td>\n      <td>1.709532</td>\n      <td>2.098650</td>\n      <td>44.891028</td>\n      <td>10108.231494</td>\n      <td>0.003058</td>\n    </tr>\n    <tr>\n      <th>1390411</th>\n      <td>1568168640</td>\n      <td>10073.50000</td>\n      <td>10073.90000</td>\n      <td>10073.50000</td>\n      <td>10073.90000</td>\n      <td>0.015000</td>\n      <td>2</td>\n      <td>10107.479924</td>\n      <td>10098.444845</td>\n      <td>-9.035079</td>\n      <td>...</td>\n      <td>96.482412</td>\n      <td>52.689484</td>\n      <td>0.30000</td>\n      <td>0.30000</td>\n      <td>0.00000</td>\n      <td>1.693871</td>\n      <td>2.075332</td>\n      <td>44.939765</td>\n      <td>10107.850033</td>\n      <td>0.003058</td>\n    </tr>\n    <tr>\n      <th>1390412</th>\n      <td>1568168700</td>\n      <td>10073.00000</td>\n      <td>10079.40000</td>\n      <td>10073.00000</td>\n      <td>10073.50000</td>\n      <td>1.249396</td>\n      <td>15</td>\n      <td>10106.918272</td>\n      <td>10097.626981</td>\n      <td>-9.291291</td>\n      <td>...</td>\n      <td>96.884422</td>\n      <td>52.979728</td>\n      <td>-0.40000</td>\n      <td>0.00000</td>\n      <td>0.40000</td>\n      <td>1.675050</td>\n      <td>2.056717</td>\n      <td>44.886242</td>\n      <td>10107.468366</td>\n      <td>0.003068</td>\n    </tr>\n  </tbody>\n</table>\n<p>1389779 rows × 28 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({0: 347066, 1: 266, -1: 113})\nCounter({0: 342221, 1: 2771, -1: 2453})\nCounter({0: 328433, 1: 10635, -1: 8377})\nCounter({0: 347445})\nCounter({0: 347445})\n"
    }
   ],
   "source": [
    "#analasis of each method\n",
    "rf_pred = ran_forest.predict(X_test.values)\n",
    "rf_weight_pred = weight_rf_forest.predict(X_test.values)\n",
    "dec_pred = dec_tree.predict(X_test.values)\n",
    "boost_pred = boost.predict(X_test.values)\n",
    "weights_boost_pred = weights_boost.predict(X_test,values)\n",
    "log_reg_pred = log_reg.predict(X_test.values)\n",
    "\n",
    "count_rf_pred = collections.Counter(rf_pred)\n",
    "count_rf_weight_pred = collections.Counter(rf_weight_pred)\n",
    "count_dec_pred = collections.Counter(dec_pred)\n",
    "count_boost_pred = collections.Counter(boost_pred)\n",
    "count_weights_boost_pred = collections.Counter(weights_boost_pred)\n",
    "count_log_pred = collections.Counter(log_reg_pred)\n",
    "\n",
    "print(count_rf_pred)\n",
    "print(count_rf_weight_pred)\n",
    "print(count_dec_pred)\n",
    "print(count_boost_pred)\n",
    "print(count_weights_boost_pred)\n",
    "print(count_log_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "<ipython-input-64-f0de0588b75b>:9: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.937017369655629"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "#dec in RF with just predict not probability of each\n",
    "RF_copy_X_train = X_train.copy()\n",
    "RF_copy_X_test = X_test.copy()\n",
    "\n",
    "RF_copy_X_train[\"dec_tree_pred\"] = dec_tree.predict(X_train.values)\n",
    "RF_copy_X_test[\"dec_tree_pred\"] = dec_tree.predict(X_test.values)\n",
    "\n",
    "rf_dec_mod = RandomForestClassifier(class_weight=class_weights, n_jobs=-1)\n",
    "rf_dec_mod.fit(RF_copy_X_train.values, y_train.values)\n",
    "rf_dec_mod.score(RF_copy_X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.937017369655629"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "#dec in boost just predict not probability of each\n",
    "boost_dec_mod = XGBClassifier(n_jobs=-1)\n",
    "boost_dec_mod.fit(RF_copy_X_train.values, y_train.values)\n",
    "boost_dec_mod.score(RF_copy_X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "<ipython-input-49-323e58ba5d1f>:9: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9735181107801235"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "#boost in RF\n",
    "RF_boost_X_train = X_train.copy()\n",
    "RF_boost_X_test = X_test.copy()\n",
    "\n",
    "RF_boost_X_train[\"boost_pred\"] = boost.predict(X_train.values)\n",
    "RF_boost_X_test[\"boost_pred\"] = boost.predict(X_test.values)\n",
    "\n",
    "rf_boost_mod = RandomForestClassifier(class_weight=class_weights, n_jobs=-1)\n",
    "rf_boost_mod.fit(RF_boost_X_train.values, y_train.values)\n",
    "rf_boost_mod.score(RF_boost_X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "<ipython-input-50-64795c7e4025>:17: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9568679934953733"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "#boost proba in rf\n",
    "RF_boost_prob_X_train = X_train.copy()\n",
    "RF_boost_prob_X_test = X_test.copy()\n",
    "\n",
    "RF_boost_prob_train_pred = boost.predict_proba(X_train.values)\n",
    "RF_boost_prob_test_pred = boost.predict_proba(X_test.values)\n",
    "\n",
    "RF_boost_prob_X_train[\"neg_val\"] = RF_boost_prob_train_pred[:,0]\n",
    "RF_boost_prob_X_train[\"zero_val\"] = RF_boost_prob_train_pred[:,1]\n",
    "RF_boost_prob_X_train[\"pos_val\"] = RF_boost_prob_train_pred[:,2]\n",
    "\n",
    "RF_boost_prob_X_test[\"neg_val\"] = RF_boost_prob_test_pred[:,0]\n",
    "RF_boost_prob_X_test[\"zero_val\"] = RF_boost_prob_test_pred[:,1]\n",
    "RF_boost_prob_X_test[\"pos_val\"] = RF_boost_prob_test_pred[:,2]\n",
    "\n",
    "rf_boost_prob_mod = RandomForestClassifier(class_weight=class_weights, n_jobs=-1)\n",
    "rf_boost_prob_mod.fit(RF_boost_prob_X_train.values, y_train.values)\n",
    "rf_boost_prob_mod.score(RF_boost_prob_X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9739584682467729"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "#RF in boost\n",
    "boost_RF_X_train = X_train.copy()\n",
    "boost_RF_X_test = X_test.copy()\n",
    "\n",
    "boost_RF_X_train[\"rf_pred\"] = weight_rf_forest.predict(X_train.values)\n",
    "boost_RF_X_test[\"rf_pred\"] = weight_rf_forest.predict(X_test.values)\n",
    "\n",
    "boost_rf_mod = XGBClassifier(n_jobs=-1)\n",
    "boost_rf_mod.fit(boost_RF_X_train.values, y_train.values)\n",
    "boost_rf_mod.score(boost_RF_X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9703492639122739"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "#rf proba in boost\n",
    "boost_RF_prob_X_train = X_train.copy()\n",
    "boost_RF_prob_X_test = X_test.copy()\n",
    "\n",
    "boost_RF_prob_train_pred = boost.predict_proba(X_train.values)\n",
    "boost_RF_prob_test_pred = boost.predict_proba(X_test.values)\n",
    "\n",
    "boost_RF_prob_X_train[\"neg_val\"] = boost_RF_prob_train_pred[:,0]\n",
    "boost_RF_prob_X_train[\"zero_val\"] = boost_RF_prob_train_pred[:,1]\n",
    "boost_RF_prob_X_train[\"pos_val\"] = boost_RF_prob_train_pred[:,2]\n",
    "\n",
    "boost_RF_prob_X_test[\"neg_val\"] = boost_RF_prob_test_pred[:,0]\n",
    "boost_RF_prob_X_test[\"zero_val\"] = boost_RF_prob_test_pred[:,1]\n",
    "boost_RF_prob_X_test[\"pos_val\"] = boost_RF_prob_test_pred[:,2]\n",
    "\n",
    "boost_rf_prob_mod = XGBClassifier(n_jobs=-1)\n",
    "boost_rf_prob_mod.fit(boost_RF_prob_X_train.values, y_train.values)\n",
    "boost_rf_prob_mod.score(boost_RF_prob_X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({0: 342036, 1: 3180, -1: 2229})\nCounter({0: 333983, 1: 9380, -1: 4082})\nCounter({0: 342221, 1: 2771, -1: 2453})\nCounter({0: 340883, 1: 5078, -1: 1484})\n"
    }
   ],
   "source": [
    "#analysis of model in model\n",
    "rf_dec_pred = rf_dec_mod.predict(RF_copy_X_test.values)\n",
    "boost_dec_pred = boost_dec_mod.predict(boost_copy_X_test.values)\n",
    "rf_boost_mod_pred = rf_boost_mod.predict(RF_boost_X_test.values)\n",
    "rf_boost_prob_mod_pred = rf_boost_prob_mod.predict(RF_boost_prob_X_test.values)\n",
    "boost_rf_mod_pred = boost_rf_mod.predict(boost_RF_X_test.values)\n",
    "boost_rf_prob_mod_pred = boost_rf_prob_mod.predict(boost_RF_prob_X_test.values)\n",
    "\n",
    "count_rf_dec = collections.Counter(rf_dec_pred)\n",
    "count_boost_dec = collections.Counter(boost_dec_pred)\n",
    "count_rf_boost_mod = collections.Counter(rf_boost_mod_pred)\n",
    "count_rf_boost_prob_mod = collections.Counter(rf_boost_prob_mod_pred)\n",
    "count_boost_rf_mod = collections.Counter(boost_rf_mod_pred)\n",
    "count_boost_rf_prob_mod = collections.Counter(boost_rf_prob_mod_pred)\n",
    "\n",
    "print(count_rf_dec)\n",
    "print(count_boost_dec)\n",
    "print(count_rf_boost_mod)\n",
    "print(count_rf_boost_prob_mod)\n",
    "print(count_boost_rf_mod)\n",
    "print(count_boost_rf_prob_mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "<ipython-input-41-d6ef2a4f357d>:18: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9356962972556807"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "#dec in RF with just predict not probability of each\n",
    "#TODO\n",
    "rf_dec_train_X = X_train.copy()\n",
    "rf_dec_test_X = X_test.copy()\n",
    "\n",
    "X_train_dec_predict = dec_tree.predict_proba(X_train.values)\n",
    "X_test_dec_predict = dec_tree.predict_proba(X_test.values)\n",
    "\n",
    "rf_dec_train_X[\"neg_weight\"] = X_train_dec_predict[:,0]\n",
    "rf_dec_train_X[\"zero_weight\"] = X_train_dec_predict[:,1]\n",
    "rf_dec_train_X[\"pos_weight\"] = X_train_dec_predict[:,2]\n",
    "\n",
    "rf_dec_test_X[\"neg_weight\"] = X_test_dec_predict[:,0]\n",
    "rf_dec_test_X[\"zero_weight\"] = X_test_dec_predict[:,1]\n",
    "rf_dec_test_X[\"pos_weight\"] = X_test_dec_predict[:,2]\n",
    "\n",
    "rf_probs_mod = RandomForestClassifier(n_jobs=-1, class_weight=class_weights)\n",
    "rf_probs_mod.fit(rf_dec_train_X.values, y_train.values)\n",
    "rf_probs_mod.score(rf_dec_test_X.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9356962972556807"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "#dec in RF with just predict not probability of each\n",
    "boost_dec_train_X = X_train.copy()\n",
    "boost_dec_test_X = X_test.copy()\n",
    "\n",
    "boost_dec_train_X[\"neg_weight\"] = X_train_dec_predict[:,0]\n",
    "boost_dec_train_X[\"zero_weight\"] = X_train_dec_predict[:,1]\n",
    "boost_dec_train_X[\"pos_weight\"] = X_train_dec_predict[:,2]\n",
    "\n",
    "boost_dec_test_X[\"neg_weight\"] = X_test_dec_predict[:,0]\n",
    "boost_dec_test_X[\"zero_weight\"] = X_test_dec_predict[:,1]\n",
    "boost_dec_test_X[\"pos_weight\"] = X_test_dec_predict[:,2]\n",
    "\n",
    "boost_probs_mod = XGBClassifier(n_jobs= -1)\n",
    "boost_probs_mod.fit(boost_dec_train_X.values, y_train.values)\n",
    "boost_probs_mod.score(boost_dec_test_X.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({0: 328433, 1: 10635, -1: 8377})\nCounter({0: 328433, 1: 10635, -1: 8377})\n"
    }
   ],
   "source": [
    "#analysis on the probability of the different models\n",
    "rf_probs_pred = rf_probs_mod.predict(rf_dec_test_X.values)\n",
    "boost_probs_pred = boost_probs_mod.predict(boost_dec_test_X.values)\n",
    "\n",
    "count_rf_probs_pred = collections.Counter(rf_probs_pred)\n",
    "count_boost_probs_pred = collections.Counter(boost_probs_pred)\n",
    "\n",
    "print(count_rf_probs_pred)\n",
    "print(count_boost_probs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "<ipython-input-21-e8da793dde59>:11: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9356962972556807"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "#two mods in RF\n",
    "rf_mult_X_train = X_train.copy()\n",
    "rf_mult_X_test = X_test.copy()\n",
    "\n",
    "rf_mult_X_train[\"dec_pred\"] = dec_tree.predict(X_train.values)\n",
    "rf_mult_X_train[\"boost_pred\"] = boost.predict(X_train.values)\n",
    "rf_mult_X_test[\"dec_pred\"] = dec_tree.predict(X_test.values)\n",
    "rf_mult_X_test[\"boost_pred\"] = boost.predict(X_test.values)\n",
    "\n",
    "rf_mult_mod = RandomForestClassifier(n_jobs=-1, class_weight=class_weights)\n",
    "rf_mult_mod.fit(rf_mult_X_train.values, y_train.values)\n",
    "rf_mult_mod.score(rf_mult_X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9356962972556807"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "boost_mult_X_train = X_train.copy()\n",
    "boost_mult_X_test = X_test.copy()\n",
    "\n",
    "boost_mult_X_train[\"dec_pred\"] = dec_tree.predict(X_train.values)\n",
    "boost_mult_X_train[\"rf_pred\"] = weight_rf_forest.predict(X_train.values)\n",
    "boost_mult_X_test[\"dec_pred\"] = dec_tree.predict(X_test.values)\n",
    "boost_mult_X_test[\"rf_pred\"] = weight_rf_forest.predict(X_test.values)\n",
    "\n",
    "boost_mult_mod = XGBClassifier(n_jobs= -1)\n",
    "boost_mult_mod.fit(boost_mult_X_train.values, y_train.values)\n",
    "boost_mult_mod.score(boost_mult_X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Counter({0: 328433, 1: 10635, -1: 8377})\nCounter({0: 328433, 1: 10635, -1: 8377})\n"
    }
   ],
   "source": [
    "#analysis of the two models in one\n",
    "rf_mult_pred = rf_mult_mod.predict(rf_mult_X_test.values)\n",
    "boost_mult_pred = boost_mult_mod.predict(boost_mult_X_test.values)\n",
    "\n",
    "count_rf_mult_pred = collections.Counter(rf_mult_pred)\n",
    "count_boost_mult_pred = collections.Counter(boost_mult_pred)\n",
    "\n",
    "print(count_rf_mult_pred)\n",
    "print(count_boost_mult_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}