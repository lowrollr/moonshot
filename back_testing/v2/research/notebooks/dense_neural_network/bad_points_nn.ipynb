{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bite16e18d3a3ed4f2a87fc5ad0fa306a0c",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/Users/rosscopeland/Desktop/personal/code/vivaldi/back_testing\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('../../../../')\n",
    "print(os.getcwd())\n",
    "from v2.strategy.indicators.optimal_v2 import Optimal_v2\n",
    "from v2.model import Trading\n",
    "from v2.strategy.indicators.param import Param\n",
    "from v2.strategy.indicators.roc import RateOfChange\n",
    "from v2.research.scripts.notebook_utils import notebookUtils\n",
    "from v2.research.scripts.scoreboard import updateScoreboard\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing as mp\n",
    "from itertools import repeat\n",
    "\n",
    "#tensorflow stuff\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "from v2.strategy.strategies.atlas.atlas_v1_2 import Atlas_v1_2\n",
    "from v2.strategy.strategies.atlas.atlas_v0_0 import Atlas_v0_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = notebookUtils()\n",
    "model_name = \"gamemaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading data from XTZ...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from MATIC...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from IOTA...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from ONT...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from ETC...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from BAT...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from ADA...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from BAND...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from BCH...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from BTC...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from chunk 9...\nLoading data from VET...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from HBAR...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from ZRX...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from ETH...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from chunk 9...\nLoading data from LTC...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from NEO...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from WAVES...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from EOS...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from XLM...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from QTUM...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from LINK...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from ZEC...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from BNB...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from NANO...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from RVN...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from ATOM...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from ONE...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from OMG...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from ZIL...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from ICX...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from ALGO...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from DOGE...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from DASH...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from ENJ...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from XRP...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\n"
    }
   ],
   "source": [
    "datasets, features, indicators = nu.loadData(indicators=[('SMA','close',''),('SMA','close','for_short'),('roc','SMA_for_short', 'shorter')],\n",
    "                            param_spec={\n",
    "                                'SMA':{'period':150}, \n",
    "                                'SMA_for_short':{'period':30}, \n",
    "                                'RateOfChange_shorter':{'period':45},\n",
    "                                },\n",
    "                            spans=[],\n",
    "                            seperate_by_coin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0052508098973872465"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "dataset = nu.multiProcessSimulateData(datasets, Atlas_v0_0)\n",
    "\n",
    "buys = dataset[dataset['is_potential_buy'] == True]\n",
    "average_profit = sum(buys['simul_profit']) / len(buys['simul_profit'])\n",
    "average_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading data from XTZ...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from MATIC...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from IOTA...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from ONT...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from ETC...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from BAT...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from ADA...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from BAND...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from BCH...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from BTC...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from chunk 9...\nLoading data from VET...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from HBAR...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from ZRX...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from ETH...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from chunk 9...\nLoading data from LTC...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from NEO...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from WAVES...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from EOS...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from XLM...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from QTUM...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from LINK...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from ZEC...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from BNB...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\nLoading data from NANO...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from RVN...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from ATOM...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from ONE...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from OMG...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from ZIL...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from ICX...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from ALGO...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from DOGE...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from DASH...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from ENJ...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from XRP...\nLoading data from chunk 0...\nLoading data from chunk 1...\nLoading data from chunk 2...\nLoading data from chunk 3...\nLoading data from chunk 4...\nLoading data from chunk 5...\nLoading data from chunk 6...\nLoading data from chunk 7...\nLoading data from chunk 8...\n"
    }
   ],
   "source": [
    "model_dataset, features, indicators = nu.loadData(indicators=[('moh', 'time', ''), ('tod', 'time', ''), ('dow', 'time', ''), ('bop', 'close', '')],\n",
    "                            param_spec={},\n",
    "                            optimal_threshold={'buy':(0.005, 0.03)},\n",
    "                            spans=[{'indicator_name':'willr',\n",
    "                                    'column_name': 'close',\n",
    "                                    'param_name': 'period',\n",
    "                                    'param_values': [10,30]},\n",
    "                                    {'indicator_name':'cci',\n",
    "                                    'column_name': 'close',\n",
    "                                    'param_name': 'period',\n",
    "                                    'param_values': [10,30,60]},\n",
    "                                    {'indicator_name':'rsi',\n",
    "                                    'column_name': 'close',\n",
    "                                    'param_name': 'period',\n",
    "                                    'param_values': [2,3,5,10,30]},\n",
    "                                    {'indicator_name':'natr',\n",
    "                                    'column_name': 'close',\n",
    "                                    'param_name': 'period',\n",
    "                                    'param_values': [30,60,120,180]},\n",
    "                                    {'indicator_name':'cmo',\n",
    "                                    'column_name': 'close',\n",
    "                                    'param_name': 'period',\n",
    "                                    'param_values': [2,3,5,10,60]}\n",
    "                                    ],\n",
    "                            scale='minmaxwindow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_dataset = model_dataset.merge(dataset, on=['time', 'open', 'high', 'low', 'close', 'volume'])\n",
    "joined_dataset = joined_dataset[joined_dataset['is_potential_buy'] == True]\n",
    "\n",
    "joined_dataset.drop([\"time\", \"open\", \"high\", \"volume\", \"low\", \"SMA\", \"SMA_for_short\", \"RateOfChange_shorter\", \"is_potential_buy\"], axis=1, inplace=True)\n",
    "\n",
    "joined_dataset.dropna(inplace=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_dataset[\"optimal\"] = joined_dataset.apply(lambda x: nu.filter_optimal(x.simul_profit, (average_profit, 1.0), 'buy'),  axis=1)\n",
    "joined_dataset.drop([\"simul_profit\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "172121"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "trainX, testX, trainy, testy = nu.splitData(joined_dataset, split_size=0.2, y_column_name=\"optimal\", shuffle_data=False, balance_unbalanced_data=True, balance_info={'multiplier_val':1, 'superset_class_val':0, 'randomize_concat':True})\n",
    "len(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: 1.0598192185017794, 1: 0.9465727358718845}"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "class_weights = nu.getWeights(trainy)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "opt = Adam(lr=1e-3, decay=1e-5)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "#stop model from training when it starts to get bad\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                min_delta=0, \n",
    "                                patience=5, \n",
    "                                verbose=0, \n",
    "                                mode='auto', \n",
    "                                baseline=None, \n",
    "                                restore_best_weights=True)\n",
    "callbacks.append(early_stop)\n",
    "\n",
    "\n",
    "# # getting the model_version name for the model checkpoint callback\n",
    "# # keep is_nn to false here so it doesn't save the model just yet\n",
    "# version_number = nu.exportModel(model, model_name, False, indicators, features, proba_threshold=0.0, is_nn=False, save_model=False)\n",
    "\n",
    "# #saving model when validation accuracy gets better\n",
    "# checkpoint_call = tf.keras.callbacks.ModelCheckpoint(f'./v2/strategy/saved_models/{model_name}/{version_number}', \n",
    "#                                      monitor='val_accuracy', \n",
    "#                                      verbose=0, \n",
    "#                                      save_best_only=True,\n",
    "#                                      save_weights_only=False, \n",
    "#                                      mode='auto', \n",
    "#                                      save_freq='epoch')\n",
    "# callbacks.append(checkpoint_call)\n",
    "\n",
    "# if not os.path.isdir(f'./v2/strategy/saved_models/{model_name}/{version_number}/logs'):\n",
    "#     os.mkdir(f'./v2/strategy/saved_models/{model_name}/{version_number}/logs')\n",
    "# tensorb = tf.keras.callbacks.TensorBoard(log_dir=f'./v2/strategy/saved_models/{model_name}/{version_number}/logs',\n",
    "#                                  histogram_freq=0, \n",
    "#                                  write_graph=True, \n",
    "#                                  write_images=False,    \n",
    "#                                  update_freq='epoch', \n",
    "#                                  profile_batch=2, \n",
    "#                                  embeddings_freq=0,    \n",
    "#                                  embeddings_metadata=None)\n",
    "# callbacks.append(tensorb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/30\n5379/5379 [==============================] - 8s 2ms/step - loss: 0.7024 - accuracy: 0.5386 - val_loss: 0.6762 - val_accuracy: 0.5859\nEpoch 2/30\n5379/5379 [==============================] - 8s 1ms/step - loss: 0.6798 - accuracy: 0.5680 - val_loss: 0.6827 - val_accuracy: 0.5644\nEpoch 3/30\n5379/5379 [==============================] - 8s 2ms/step - loss: 0.6768 - accuracy: 0.5768 - val_loss: 0.6804 - val_accuracy: 0.5571\nEpoch 4/30\n5379/5379 [==============================] - 8s 2ms/step - loss: 0.6748 - accuracy: 0.5809 - val_loss: 0.6768 - val_accuracy: 0.5712\nEpoch 5/30\n5379/5379 [==============================] - 8s 2ms/step - loss: 0.6731 - accuracy: 0.5832 - val_loss: 0.6728 - val_accuracy: 0.5831\nEpoch 6/30\n5379/5379 [==============================] - 9s 2ms/step - loss: 0.6725 - accuracy: 0.5855 - val_loss: 0.6855 - val_accuracy: 0.5498\nEpoch 7/30\n5379/5379 [==============================] - 8s 2ms/step - loss: 0.6719 - accuracy: 0.5861 - val_loss: 0.6766 - val_accuracy: 0.5605\nEpoch 8/30\n5379/5379 [==============================] - 8s 2ms/step - loss: 0.6709 - accuracy: 0.5877 - val_loss: 0.6744 - val_accuracy: 0.5797\nEpoch 9/30\n5379/5379 [==============================] - 9s 2ms/step - loss: 0.6705 - accuracy: 0.5875 - val_loss: 0.6757 - val_accuracy: 0.5721\nEpoch 10/30\n5379/5379 [==============================] - 8s 2ms/step - loss: 0.6703 - accuracy: 0.5887 - val_loss: 0.6750 - val_accuracy: 0.5733\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x15868c910>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "model.fit(trainX.drop(\"close\", axis=1).values, trainy.values, callbacks=callbacks, epochs=30, class_weight=class_weights, validation_data=(testX.drop('close', axis=1).values, testy.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Library/Python/3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: ./v2/strategy/saved_models/gamemaker/1_1/assets\n"
    }
   ],
   "source": [
    "model_version = nu.exportModel(model, model_name, new_version=False, indicators=indicators, features=features, proba_threshold=0.7, is_nn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}