{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38564bitbf960d00bf8447f58cc83a94e3f130e4",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/Users/rosscopeland/Desktop/personal/code/vivaldi/back_testing\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('../../../../')\n",
    "print(os.getcwd())\n",
    "from v2.strategy.indicators.optimal_v2 import Optimal_v2\n",
    "from v2.model import Trading\n",
    "from v2.strategy.indicators.param import Param\n",
    "from v2.strategy.indicators.notebook_utils import fetchIndicators, genDataForAll\n",
    "from load_config import load_config\n",
    "from v2.strategy.indicators.momentum import Momentum\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "BTCUSDT-1m\ntook 3.105715036392212 seconds\ntook 1.2462499141693115 seconds\ntook 3.3135530948638916 seconds\ntook 2.796541213989258 seconds\ntook 3.2370030879974365 seconds\ntook 1.4775080680847168 seconds\ntook 2.118920087814331 seconds\ntook 1.951470136642456 seconds\ntook 2.0174741744995117 seconds\ntook 1.6485209465026855 seconds\ntook 1.452357292175293 seconds\ntook 3.529942035675049 seconds\nETHUSDT-1m\ntook 2.746431827545166 seconds\ntook 1.145374059677124 seconds\ntook 3.1037020683288574 seconds\ntook 2.631814956665039 seconds\ntook 3.2427399158477783 seconds\ntook 1.4297549724578857 seconds\ntook 2.1192169189453125 seconds\ntook 2.017275810241699 seconds\ntook 1.8947150707244873 seconds\ntook 1.7187519073486328 seconds\ntook 1.4568970203399658 seconds\ntook 3.5595080852508545 seconds\nXRPUSDT-1m\ntook 1.197274923324585 seconds\ntook 2.5740437507629395 seconds\ntook 3.2869532108306885 seconds\ntook 1.6001520156860352 seconds\ntook 2.2082509994506836 seconds\ntook 1.9521808624267578 seconds\ntook 2.0133557319641113 seconds\ntook 1.6444239616394043 seconds\ntook 1.4106237888336182 seconds\ntook 3.5599968433380127 seconds\nADAUSDT-1m\ntook 1.5802078247070312 seconds\ntook 2.6322481632232666 seconds\ntook 3.2597010135650635 seconds\ntook 1.4187028408050537 seconds\ntook 2.0042672157287598 seconds\ntook 2.0333409309387207 seconds\ntook 1.8929872512817383 seconds\ntook 1.7287518978118896 seconds\ntook 1.4814846515655518 seconds\ntook 3.562567949295044 seconds\nLTCUSDT-1m\ntook 1.2858009338378906 seconds\ntook 3.094614028930664 seconds\ntook 2.6977028846740723 seconds\ntook 3.270688056945801 seconds\ntook 1.4920570850372314 seconds\ntook 2.1170952320098877 seconds\ntook 1.9771008491516113 seconds\ntook 2.0192747116088867 seconds\ntook 1.6596710681915283 seconds\ntook 1.4699978828430176 seconds\ntook 3.5557518005371094 seconds\nUNIUSDT-1m\ntook 1.6483008861541748 seconds\nVETUSDT-1m\ntook 1.9220342636108398 seconds\ntook 3.2793760299682617 seconds\ntook 1.4531641006469727 seconds\ntook 1.9848010540008545 seconds\ntook 1.996863842010498 seconds\ntook 1.8926899433135986 seconds\ntook 1.707961082458496 seconds\ntook 1.464613914489746 seconds\ntook 3.5461220741271973 seconds\nXLMUSDT-1m\ntook 3.0802319049835205 seconds\ntook 3.229310989379883 seconds\ntook 1.4733531475067139 seconds\ntook 2.126073122024536 seconds\ntook 1.9356870651245117 seconds\ntook 2.009284019470215 seconds\ntook 1.6727681159973145 seconds\ntook 1.4685349464416504 seconds\ntook 3.9555859565734863 seconds\nBNBUSDT-1m\ntook 1.395456075668335 seconds\ntook 4.078520059585571 seconds\ntook 2.7910547256469727 seconds\ntook 3.262200117111206 seconds\ntook 1.4963719844818115 seconds\ntook 2.170793056488037 seconds\ntook 2.1012909412384033 seconds\ntook 2.032128095626831 seconds\ntook 1.8854913711547852 seconds\ntook 1.5317411422729492 seconds\ntook 3.5447542667388916 seconds\nBCHUSDT-1m\ntook 1.6096971035003662 seconds\ntook 1.7152788639068604 seconds\ntook 1.501629114151001 seconds\ntook 3.5853567123413086 seconds\nCOMPUSDT-1m\ntook 3.564293146133423 seconds\nATOMUSDT-1m\ntook 2.390432119369507 seconds\ntook 1.9820928573608398 seconds\ntook 1.9123551845550537 seconds\ntook 1.7107040882110596 seconds\ntook 1.4764957427978516 seconds\ntook 3.573683738708496 seconds\nBATUSDT-1m\ntook 1.575441837310791 seconds\ntook 2.026401996612549 seconds\ntook 1.8743112087249756 seconds\ntook 1.9633400440216064 seconds\ntook 1.6528971195220947 seconds\ntook 1.4187419414520264 seconds\ntook 3.5621178150177 seconds\nEGLDUSDT-1m\ntook 2.0536420345306396 seconds\nETCUSDT-1m\ntook 3.1180379390716553 seconds\ntook 3.3756611347198486 seconds\ntook 1.4429681301116943 seconds\ntook 2.0679941177368164 seconds\ntook 1.9398388862609863 seconds\ntook 2.0281989574432373 seconds\ntook 1.6811010837554932 seconds\ntook 1.4859330654144287 seconds\ntook 3.558837652206421 seconds\n"
    }
   ],
   "source": [
    "#adding in indicators\n",
    "model = Trading(load_config(\"config.hjson\"))\n",
    "dataset_list = []\n",
    "\n",
    "for list_d, name in model.df_groups:\n",
    "    inter_df_list = []\n",
    "    print(name)\n",
    "    for d in list_d:\n",
    "        now = time.time()\n",
    "        cur_dataset = d\n",
    "        my_inds = fetchIndicators(['stochastic_oscillator', 'variance','rsi', 'cci', 'ema', 'psar', 'beta', 'natr', 'macd', 'sma', 'smma', 'optimal_v2'])\n",
    "        genDataForAll(cur_dataset, my_inds)\n",
    "        mom_ind = Momentum(_params=[Param(2, 1000, 0, 'period', 15)])\n",
    "        mom_ind.genData(cur_dataset, gen_new_values=False)\n",
    "        cur_dataset.dropna(inplace=True)\n",
    "        mm_scalar = MinMaxScaler()\n",
    "        # cur_dataset[[\"rsi\", \"stosc_k\", \"stosc_d\"]] = mm_scalar.fit_transform(cur_dataset[[\"rsi\", \"stosc_k\", \"stosc_d\"]])\n",
    "        inter_df_list.append(cur_dataset)\n",
    "        print(\"took {} seconds\".format(time.time() - now))\n",
    "    inter_df_list = pd.concat(inter_df_list)\n",
    "    mm_scalar = MinMaxScaler()\n",
    "    inter_df_list[['slowk', 'slowd', 'Variance', 'RSI', 'CCI', 'EMA', 'PSAR', 'Beta', 'NATR',\n",
    "       'MACD', 'MACD_signal', 'MACD_hist', 'SMA', 'SMMA', 'Momentum']] = mm_scalar.fit_transform(inter_df_list[['slowk', 'slowd', 'Variance', 'RSI', 'CCI', 'EMA', 'PSAR', 'Beta', 'NATR',\n",
    "       'MACD', 'MACD_signal', 'MACD_hist', 'SMA', 'SMMA', 'Momentum']])\n",
    "    dataset_list.append(inter_df_list)\n",
    "final_dataset = pd.concat(dataset_list)\n",
    "\n",
    "#first try 172.11971712112427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 time       high        low        close       open  \\\n708     1502985059999  4423.6300  4423.6300  4422.065949  4423.6300   \n709     1502985119999  4423.6300  4423.6300  4422.847975  4423.6300   \n710     1502985179999  4412.3800  4412.3800  4417.613987  4412.3800   \n711     1502985239999  4412.3800  4377.5400  4397.576994  4412.3800   \n712     1502985299999  4410.3500  4371.4500  4384.513497  4377.5400   \n...               ...        ...        ...          ...        ...   \n223224  1606715999999     6.5438     6.5438     6.543045     6.5438   \n223225  1606719659999     6.5426     6.5321     6.537573     6.5375   \n223226  1606719719999     6.5350     6.5266     6.532086     6.5350   \n223227  1606719779999     6.5287     6.5211     6.527093     6.5268   \n223228  1606719839999     6.5199     6.4960     6.513397     6.5192   \n\n             volume     slowk     slowd  Variance       RSI  ...      NATR  \\\n708        0.321789  0.579117  0.770680  0.002002  0.465860  ...  0.059106   \n709        0.127402  0.576326  0.769949  0.002019  0.465860  ...  0.055161   \n710        0.757878  0.573026  0.769196  0.002052  0.443401  ...  0.055745   \n711        1.709299  0.568152  0.768416  0.002166  0.382338  ...  0.065347   \n712        0.607785  0.563119  0.767608  0.002295  0.372792  ...  0.075503   \n...             ...       ...       ...       ...       ...  ...       ...   \n223224     7.830000  0.608098  0.744970  0.000320  0.558444  ...  0.025388   \n223225   924.510000  0.607436  0.744119  0.000319  0.544192  ...  0.027047   \n223226   521.450000  0.606430  0.743275  0.000324  0.537667  ...  0.027642   \n223227  3475.220000  0.605283  0.742438  0.000333  0.532385  ...  0.027969   \n223228  5037.820000  0.604433  0.741609  0.000361  0.507286  ...  0.033612   \n\n            MACD  MACD_signal  MACD_hist       SMA      SMMA   optimal  \\\n708     0.531440     0.567140   0.554448  0.092017  0.089561  0.000000   \n709     0.531251     0.567025   0.554292  0.091993  0.089548 -0.943649   \n710     0.531014     0.566909   0.554062  0.091961  0.089527  0.000000   \n711     0.530622     0.566790   0.553598  0.091900  0.089484  0.000000   \n712     0.530208     0.566669   0.553101  0.091836  0.089437  0.000000   \n...          ...          ...        ...       ...       ...       ...   \n223224  0.541719     0.563212   0.503694  0.192989  0.193979 -0.524680   \n223225  0.541460     0.563227   0.503232  0.192990  0.193964  0.000000   \n223226  0.541181     0.563240   0.502738  0.192985  0.193945  0.000000   \n223227  0.540885     0.563250   0.502218  0.192974  0.193923  0.000000   \n223228  0.540500     0.563257   0.501550  0.192950  0.193886  0.000000   \n\n        Momentum  optimal_buy  optimal_sell  \n708     0.518795          0.0      0.000000  \n709     0.523655          0.0      0.943649  \n710     0.524121          0.0      0.000000  \n711     0.518874          0.0      0.000000  \n712     0.516144          0.0      0.000000  \n...          ...          ...           ...  \n223224  0.381182          0.0      0.524680  \n223225  0.379928          0.0      0.000000  \n223226  0.378370          0.0      0.000000  \n223227  0.377146          0.0      0.000000  \n223228  0.373116          0.0      0.000000  \n\n[15828623 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>open</th>\n      <th>volume</th>\n      <th>slowk</th>\n      <th>slowd</th>\n      <th>Variance</th>\n      <th>RSI</th>\n      <th>...</th>\n      <th>NATR</th>\n      <th>MACD</th>\n      <th>MACD_signal</th>\n      <th>MACD_hist</th>\n      <th>SMA</th>\n      <th>SMMA</th>\n      <th>optimal</th>\n      <th>Momentum</th>\n      <th>optimal_buy</th>\n      <th>optimal_sell</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>708</th>\n      <td>1502985059999</td>\n      <td>4423.6300</td>\n      <td>4423.6300</td>\n      <td>4422.065949</td>\n      <td>4423.6300</td>\n      <td>0.321789</td>\n      <td>0.579117</td>\n      <td>0.770680</td>\n      <td>0.002002</td>\n      <td>0.465860</td>\n      <td>...</td>\n      <td>0.059106</td>\n      <td>0.531440</td>\n      <td>0.567140</td>\n      <td>0.554448</td>\n      <td>0.092017</td>\n      <td>0.089561</td>\n      <td>0.000000</td>\n      <td>0.518795</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>709</th>\n      <td>1502985119999</td>\n      <td>4423.6300</td>\n      <td>4423.6300</td>\n      <td>4422.847975</td>\n      <td>4423.6300</td>\n      <td>0.127402</td>\n      <td>0.576326</td>\n      <td>0.769949</td>\n      <td>0.002019</td>\n      <td>0.465860</td>\n      <td>...</td>\n      <td>0.055161</td>\n      <td>0.531251</td>\n      <td>0.567025</td>\n      <td>0.554292</td>\n      <td>0.091993</td>\n      <td>0.089548</td>\n      <td>-0.943649</td>\n      <td>0.523655</td>\n      <td>0.0</td>\n      <td>0.943649</td>\n    </tr>\n    <tr>\n      <th>710</th>\n      <td>1502985179999</td>\n      <td>4412.3800</td>\n      <td>4412.3800</td>\n      <td>4417.613987</td>\n      <td>4412.3800</td>\n      <td>0.757878</td>\n      <td>0.573026</td>\n      <td>0.769196</td>\n      <td>0.002052</td>\n      <td>0.443401</td>\n      <td>...</td>\n      <td>0.055745</td>\n      <td>0.531014</td>\n      <td>0.566909</td>\n      <td>0.554062</td>\n      <td>0.091961</td>\n      <td>0.089527</td>\n      <td>0.000000</td>\n      <td>0.524121</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>711</th>\n      <td>1502985239999</td>\n      <td>4412.3800</td>\n      <td>4377.5400</td>\n      <td>4397.576994</td>\n      <td>4412.3800</td>\n      <td>1.709299</td>\n      <td>0.568152</td>\n      <td>0.768416</td>\n      <td>0.002166</td>\n      <td>0.382338</td>\n      <td>...</td>\n      <td>0.065347</td>\n      <td>0.530622</td>\n      <td>0.566790</td>\n      <td>0.553598</td>\n      <td>0.091900</td>\n      <td>0.089484</td>\n      <td>0.000000</td>\n      <td>0.518874</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>712</th>\n      <td>1502985299999</td>\n      <td>4410.3500</td>\n      <td>4371.4500</td>\n      <td>4384.513497</td>\n      <td>4377.5400</td>\n      <td>0.607785</td>\n      <td>0.563119</td>\n      <td>0.767608</td>\n      <td>0.002295</td>\n      <td>0.372792</td>\n      <td>...</td>\n      <td>0.075503</td>\n      <td>0.530208</td>\n      <td>0.566669</td>\n      <td>0.553101</td>\n      <td>0.091836</td>\n      <td>0.089437</td>\n      <td>0.000000</td>\n      <td>0.516144</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>223224</th>\n      <td>1606715999999</td>\n      <td>6.5438</td>\n      <td>6.5438</td>\n      <td>6.543045</td>\n      <td>6.5438</td>\n      <td>7.830000</td>\n      <td>0.608098</td>\n      <td>0.744970</td>\n      <td>0.000320</td>\n      <td>0.558444</td>\n      <td>...</td>\n      <td>0.025388</td>\n      <td>0.541719</td>\n      <td>0.563212</td>\n      <td>0.503694</td>\n      <td>0.192989</td>\n      <td>0.193979</td>\n      <td>-0.524680</td>\n      <td>0.381182</td>\n      <td>0.0</td>\n      <td>0.524680</td>\n    </tr>\n    <tr>\n      <th>223225</th>\n      <td>1606719659999</td>\n      <td>6.5426</td>\n      <td>6.5321</td>\n      <td>6.537573</td>\n      <td>6.5375</td>\n      <td>924.510000</td>\n      <td>0.607436</td>\n      <td>0.744119</td>\n      <td>0.000319</td>\n      <td>0.544192</td>\n      <td>...</td>\n      <td>0.027047</td>\n      <td>0.541460</td>\n      <td>0.563227</td>\n      <td>0.503232</td>\n      <td>0.192990</td>\n      <td>0.193964</td>\n      <td>0.000000</td>\n      <td>0.379928</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>223226</th>\n      <td>1606719719999</td>\n      <td>6.5350</td>\n      <td>6.5266</td>\n      <td>6.532086</td>\n      <td>6.5350</td>\n      <td>521.450000</td>\n      <td>0.606430</td>\n      <td>0.743275</td>\n      <td>0.000324</td>\n      <td>0.537667</td>\n      <td>...</td>\n      <td>0.027642</td>\n      <td>0.541181</td>\n      <td>0.563240</td>\n      <td>0.502738</td>\n      <td>0.192985</td>\n      <td>0.193945</td>\n      <td>0.000000</td>\n      <td>0.378370</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>223227</th>\n      <td>1606719779999</td>\n      <td>6.5287</td>\n      <td>6.5211</td>\n      <td>6.527093</td>\n      <td>6.5268</td>\n      <td>3475.220000</td>\n      <td>0.605283</td>\n      <td>0.742438</td>\n      <td>0.000333</td>\n      <td>0.532385</td>\n      <td>...</td>\n      <td>0.027969</td>\n      <td>0.540885</td>\n      <td>0.563250</td>\n      <td>0.502218</td>\n      <td>0.192974</td>\n      <td>0.193923</td>\n      <td>0.000000</td>\n      <td>0.377146</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>223228</th>\n      <td>1606719839999</td>\n      <td>6.5199</td>\n      <td>6.4960</td>\n      <td>6.513397</td>\n      <td>6.5192</td>\n      <td>5037.820000</td>\n      <td>0.604433</td>\n      <td>0.741609</td>\n      <td>0.000361</td>\n      <td>0.507286</td>\n      <td>...</td>\n      <td>0.033612</td>\n      <td>0.540500</td>\n      <td>0.563257</td>\n      <td>0.501550</td>\n      <td>0.192950</td>\n      <td>0.193886</td>\n      <td>0.000000</td>\n      <td>0.373116</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>15828623 rows × 24 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "def filter_optimal_buy(optimal):\n",
    "    if optimal > 0.0:\n",
    "        return abs(optimal)\n",
    "    return 0.0\n",
    "\n",
    "def filter_optimal_sell(optimal):\n",
    "    if optimal < 0.0:\n",
    "        return abs(optimal)\n",
    "    return 0.0\n",
    "\n",
    "# for dataset, name in model.dfs:\n",
    "#     dataset['optimal'] = dataset.apply(lambda x: filter_optimal(x.optimal), axis=1)\n",
    "final_dataset['optimal_buy'] = final_dataset.apply(lambda x: filter_optimal_buy(x.optimal), axis=1)\n",
    "final_dataset['optimal_sell'] = final_dataset.apply(lambda x: filter_optimal_sell(x.optimal), axis=1)\n",
    "final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              close     slowk     slowd  Variance       RSI       CCI  \\\n708     4422.065949  0.579117  0.770680  0.002002  0.465860  0.489886   \n709     4422.847975  0.576326  0.769949  0.002019  0.465860  0.490330   \n710     4417.613987  0.573026  0.769196  0.002052  0.443401  0.484324   \n711     4397.576994  0.568152  0.768416  0.002166  0.382338  0.471841   \n712     4384.513497  0.563119  0.767608  0.002295  0.372792  0.470264   \n...             ...       ...       ...       ...       ...       ...   \n223224     6.543045  0.608098  0.744970  0.000320  0.558444  0.473253   \n223225     6.537573  0.607436  0.744119  0.000319  0.544192  0.465436   \n223226     6.532086  0.606430  0.743275  0.000324  0.537667  0.460534   \n223227     6.527093  0.605283  0.742438  0.000333  0.532385  0.457032   \n223228     6.513397  0.604433  0.741609  0.000361  0.507286  0.442555   \n\n             EMA      PSAR      Beta      NATR      MACD  MACD_signal  \\\n708     0.090894  0.555061  0.416967  0.059106  0.531440     0.567140   \n709     0.090874  0.555061  0.416905  0.055161  0.531251     0.567025   \n710     0.090840  0.555433  0.416405  0.055745  0.531014     0.566909   \n711     0.090761  0.556585  0.412223  0.065347  0.530622     0.566790   \n712     0.090676  0.556786  0.412168  0.075503  0.530208     0.566669   \n...          ...       ...       ...       ...       ...          ...   \n223224  0.194032  0.538971  0.514761  0.025388  0.541719     0.563212   \n223225  0.193994  0.539515  0.519181  0.027047  0.541460     0.563227   \n223226  0.193948  0.539770  0.516984  0.027642  0.541181     0.563240   \n223227  0.193898  0.539979  0.513520  0.027969  0.540885     0.563250   \n223228  0.193819  0.541020  0.518030  0.033612  0.540500     0.563257   \n\n        MACD_hist       SMA      SMMA  Momentum  optimal_buy  optimal_sell  \n708      0.554448  0.092017  0.089561  0.518795          0.0      0.000000  \n709      0.554292  0.091993  0.089548  0.523655          0.0      0.943649  \n710      0.554062  0.091961  0.089527  0.524121          0.0      0.000000  \n711      0.553598  0.091900  0.089484  0.518874          0.0      0.000000  \n712      0.553101  0.091836  0.089437  0.516144          0.0      0.000000  \n...           ...       ...       ...       ...          ...           ...  \n223224   0.503694  0.192989  0.193979  0.381182          0.0      0.524680  \n223225   0.503232  0.192990  0.193964  0.379928          0.0      0.000000  \n223226   0.502738  0.192985  0.193945  0.378370          0.0      0.000000  \n223227   0.502218  0.192974  0.193923  0.377146          0.0      0.000000  \n223228   0.501550  0.192950  0.193886  0.373116          0.0      0.000000  \n\n[15828623 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>close</th>\n      <th>slowk</th>\n      <th>slowd</th>\n      <th>Variance</th>\n      <th>RSI</th>\n      <th>CCI</th>\n      <th>EMA</th>\n      <th>PSAR</th>\n      <th>Beta</th>\n      <th>NATR</th>\n      <th>MACD</th>\n      <th>MACD_signal</th>\n      <th>MACD_hist</th>\n      <th>SMA</th>\n      <th>SMMA</th>\n      <th>Momentum</th>\n      <th>optimal_buy</th>\n      <th>optimal_sell</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>708</th>\n      <td>4422.065949</td>\n      <td>0.579117</td>\n      <td>0.770680</td>\n      <td>0.002002</td>\n      <td>0.465860</td>\n      <td>0.489886</td>\n      <td>0.090894</td>\n      <td>0.555061</td>\n      <td>0.416967</td>\n      <td>0.059106</td>\n      <td>0.531440</td>\n      <td>0.567140</td>\n      <td>0.554448</td>\n      <td>0.092017</td>\n      <td>0.089561</td>\n      <td>0.518795</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>709</th>\n      <td>4422.847975</td>\n      <td>0.576326</td>\n      <td>0.769949</td>\n      <td>0.002019</td>\n      <td>0.465860</td>\n      <td>0.490330</td>\n      <td>0.090874</td>\n      <td>0.555061</td>\n      <td>0.416905</td>\n      <td>0.055161</td>\n      <td>0.531251</td>\n      <td>0.567025</td>\n      <td>0.554292</td>\n      <td>0.091993</td>\n      <td>0.089548</td>\n      <td>0.523655</td>\n      <td>0.0</td>\n      <td>0.943649</td>\n    </tr>\n    <tr>\n      <th>710</th>\n      <td>4417.613987</td>\n      <td>0.573026</td>\n      <td>0.769196</td>\n      <td>0.002052</td>\n      <td>0.443401</td>\n      <td>0.484324</td>\n      <td>0.090840</td>\n      <td>0.555433</td>\n      <td>0.416405</td>\n      <td>0.055745</td>\n      <td>0.531014</td>\n      <td>0.566909</td>\n      <td>0.554062</td>\n      <td>0.091961</td>\n      <td>0.089527</td>\n      <td>0.524121</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>711</th>\n      <td>4397.576994</td>\n      <td>0.568152</td>\n      <td>0.768416</td>\n      <td>0.002166</td>\n      <td>0.382338</td>\n      <td>0.471841</td>\n      <td>0.090761</td>\n      <td>0.556585</td>\n      <td>0.412223</td>\n      <td>0.065347</td>\n      <td>0.530622</td>\n      <td>0.566790</td>\n      <td>0.553598</td>\n      <td>0.091900</td>\n      <td>0.089484</td>\n      <td>0.518874</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>712</th>\n      <td>4384.513497</td>\n      <td>0.563119</td>\n      <td>0.767608</td>\n      <td>0.002295</td>\n      <td>0.372792</td>\n      <td>0.470264</td>\n      <td>0.090676</td>\n      <td>0.556786</td>\n      <td>0.412168</td>\n      <td>0.075503</td>\n      <td>0.530208</td>\n      <td>0.566669</td>\n      <td>0.553101</td>\n      <td>0.091836</td>\n      <td>0.089437</td>\n      <td>0.516144</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>223224</th>\n      <td>6.543045</td>\n      <td>0.608098</td>\n      <td>0.744970</td>\n      <td>0.000320</td>\n      <td>0.558444</td>\n      <td>0.473253</td>\n      <td>0.194032</td>\n      <td>0.538971</td>\n      <td>0.514761</td>\n      <td>0.025388</td>\n      <td>0.541719</td>\n      <td>0.563212</td>\n      <td>0.503694</td>\n      <td>0.192989</td>\n      <td>0.193979</td>\n      <td>0.381182</td>\n      <td>0.0</td>\n      <td>0.524680</td>\n    </tr>\n    <tr>\n      <th>223225</th>\n      <td>6.537573</td>\n      <td>0.607436</td>\n      <td>0.744119</td>\n      <td>0.000319</td>\n      <td>0.544192</td>\n      <td>0.465436</td>\n      <td>0.193994</td>\n      <td>0.539515</td>\n      <td>0.519181</td>\n      <td>0.027047</td>\n      <td>0.541460</td>\n      <td>0.563227</td>\n      <td>0.503232</td>\n      <td>0.192990</td>\n      <td>0.193964</td>\n      <td>0.379928</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>223226</th>\n      <td>6.532086</td>\n      <td>0.606430</td>\n      <td>0.743275</td>\n      <td>0.000324</td>\n      <td>0.537667</td>\n      <td>0.460534</td>\n      <td>0.193948</td>\n      <td>0.539770</td>\n      <td>0.516984</td>\n      <td>0.027642</td>\n      <td>0.541181</td>\n      <td>0.563240</td>\n      <td>0.502738</td>\n      <td>0.192985</td>\n      <td>0.193945</td>\n      <td>0.378370</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>223227</th>\n      <td>6.527093</td>\n      <td>0.605283</td>\n      <td>0.742438</td>\n      <td>0.000333</td>\n      <td>0.532385</td>\n      <td>0.457032</td>\n      <td>0.193898</td>\n      <td>0.539979</td>\n      <td>0.513520</td>\n      <td>0.027969</td>\n      <td>0.540885</td>\n      <td>0.563250</td>\n      <td>0.502218</td>\n      <td>0.192974</td>\n      <td>0.193923</td>\n      <td>0.377146</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>223228</th>\n      <td>6.513397</td>\n      <td>0.604433</td>\n      <td>0.741609</td>\n      <td>0.000361</td>\n      <td>0.507286</td>\n      <td>0.442555</td>\n      <td>0.193819</td>\n      <td>0.541020</td>\n      <td>0.518030</td>\n      <td>0.033612</td>\n      <td>0.540500</td>\n      <td>0.563257</td>\n      <td>0.501550</td>\n      <td>0.192950</td>\n      <td>0.193886</td>\n      <td>0.373116</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>15828623 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "dataset = final_dataset.drop([\"optimal\",\"volume\", \"time\", \"high\", \"low\", \"open\"], axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop([\"optimal_buy\", \"optimal_sell\", \"close\"], axis=1)\n",
    "\n",
    "buy_train_y= train[[\"optimal_buy\"]]\n",
    "sell_train_y = train[[\"optimal_sell\"]]\n",
    "\n",
    "test_X = test.drop([\"optimal_buy\", \"optimal_sell\", \"close\"], axis=1)\n",
    "\n",
    "buy_test_y= test[[\"optimal_buy\"]]\n",
    "sell_test_y = test[[\"optimal_sell\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d08e8a5a2242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf_buy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m69420\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, n_estimators=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf_buy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuy_train_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score of classifer is {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_buy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuy_test_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    387\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#making more simple classifer as a baseline\n",
    "clf_buy = RandomForestRegressor(random_state=69420, n_jobs=-1, min_samples_leaf=2)#, n_estimators=10)\n",
    "\n",
    "clf_buy.fit(train_X.values, buy_train_y.values)\n",
    "\n",
    "print(\"Score of classifer is {} \".format(clf_buy.score(test_X.values, buy_test_y.values)))\n",
    "\n",
    "for i, v in enumerate(clf_buy.feature_importances_):\n",
    "    print('i: {}, Feature: {}, Score: {}'.format(i, balanced_data_X.columns[i], clf_buy.feature_importances_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making more simple classifer as a baseline\n",
    "clf_sell = RandomForestRegressor(random_state=69420, n_jobs=-1, min_samples_leaf=2)#, n_estimators=10)\n",
    "\n",
    "clf_sell.fit(train_X.values, sell_train_y.values)\n",
    "\n",
    "print(\"Score of classifer is {} \".format(clf_sell.score(test_X.values, sell_test_y.values)))\n",
    "\n",
    "for i, v in enumerate(clf_sell.feature_importances_):\n",
    "    print('i: {}, Feature: {}, Score: {}'.format(i, balanced_data_X.columns[i], clf_sell.feature_importances_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_buys(row):\n",
    "    if row.predict_buy > 0.5:\n",
    "        return row.close\n",
    "    # if row.predict == 2.0 :# and heat_val > 0.6:\n",
    "    #     return row.close\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def insert_sells(row):\n",
    "    if row.predict_sell > 0.5:\n",
    "        return row.close\n",
    "    # if row.predict == 0.0:\n",
    "    #     return row.close\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph = test.drop([\"optimal_sell\", \"optimal_buy\"], axis=1)\n",
    "test_graph.dropna(inplace=True)\n",
    "test_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph[\"predict_sell\"] = clf_sell.predict_proba(test_X.values)[:,1]\n",
    "test_graph[\"predict_buy\"] = clf_buy.predict_proba(test_X.values)[:,1]\n",
    "\n",
    "test_graph[\"sell\"] = test_graph.apply(lambda x: insert_sells(x), axis=1)\n",
    "test_graph[\"buy\"] = test_graph.apply(lambda x: insert_buys(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_amnt = test_graph[3000:5000]\n",
    "first_amnt.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# axes = plt.gca()\n",
    "# axes.set_ylim([0,10000])\n",
    "\n",
    "\n",
    "plt.scatter(x=first_amnt.index, y=first_amnt['buy'], color='green')\n",
    "plt.scatter(x=first_amnt.index, y=first_amnt['sell'], color='red')\n",
    "\n",
    "plt.plot(first_amnt.index, first_amnt['close'], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}